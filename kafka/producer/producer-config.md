
### 生产者配置

**SyncProducerConfigShared**

| 配置参数 | 类型 | 默认值 | 说明 |
| --- | --- | --- | --- |
| `send.buffer.bytes` | int | 100*1024 |  |
| `client.id` | string | "" | the client application sending the producer requests |
| `request.required.acks` | enum | 0 | `0` - means the producer will not wait for any acknowledgement from the leader <br> `1` - means the leader will write the message to its local log and immediately acknowledge <br> `-1` - means the leader will wait for acknowledgement from all in-sync replicas before acknowledging the write |
| `request.timeout.ms` | int | 10000 | The ack timeout of the producer requests. Value must be non-negative and non-zero. |



**SyncProducerConfig**

| 配置参数 | 类型 | 默认值 | 说明 |
| --- | --- | --- | --- |
| `host` | string | - | the broker to which the producer sends events |
| `port` | int | - | the port on which the broker is running |

**AsyncProducerConfig**

| 配置参数 | 类型 | 默认值 | 说明 |
| --- | --- | --- | --- |
| `queue.buffering.max.ms` | int | 5000 | maximum time, in milliseconds, for buffering data on the producer queue |
| `queue.buffering.max.messages` | int | 10000 | the maximum size of the blocking queue for buffering on the producer |
| `queue.enqueue.timeout.ms` | int | -1 | Timeout for event enqueue. <br> `0`: events will be enqueued immediately or dropped if the queue is full <br> `-ve`: enqueue will block indefinitely if the queue is full <br> `+ve`: enqueue will block up to this many milliseconds if the queue is full |
| `batch.num.messages` | int | 200 | the number of messages batched at the producer |
| `serializer.class` | string | kafka.serializer.DefaultEncoder | the serializer class for values |
| `key.serializer.class` | string | kafka.serializer.DefaultEncoder | the serializer class for keys |

**ProducerConfig**

| 配置参数 | 类型 | 默认值 | 说明 |
| --- | --- | --- | --- |
| `metadata.broker.list` | string | | This is for bootstrapping and the producer will only use it for getting metadata (topics, partitions and replicas). The socket connections for sending the actual data will be established based on the broker information returned in the metadata. The format is **host1:port1,host2:port2**, and the list can be a subset of brokers or a VIP pointing to a subset of brokers. |
| `partitioner.class` | string | kafka.producer.DefaultPartitioner | the partitioner class for partitioning events amongst sub-topics |
| `producer.type` | enum | sync | this parameter specifies whether the messages are sent asynchronously or not. Valid values are: **async** and **sync**. |
| `compression.codec` | string | none | This parameter allows you to specify the compression codec for all data generated by this producer. |
| `compressed.topics` | string |  | This parameter allows you to set whether compression should be turned on for particular topics |
| `message.send.max.retries` | int | 3 | The leader may be unavailable transiently, which can fail the sending of a message. This property specifies the number of retries when such failures occur. |
| `retry.backoff.ms` | int | 100 | Before each retry, the producer refreshes the metadata of relevant topics. Since leader election takes a bit of time, this property specifies the amount of time that the producer waits before refreshing the metadata. |
| `topic.metadata.refresh.interval.ms` | int | 600000 | The producer generally refreshes the topic metadata from brokers when there is a failure (partition missing, leader not available...). It will also poll regularly (default: every 10min so 600000ms). If you set this to a negative value, metadata will only get refreshed on failure. If you set this to zero, the metadata will get refreshed after each message sent (not recommended). Important note: the refresh happen only AFTER the message is sent, so if the producer never sends a message the metadata is never refreshed |

